{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Dates\n",
    "import datetime\n",
    "import time\n",
    "import julian\n",
    "\n",
    "# Database\n",
    "import sqlite3\n",
    "import spatialite\n",
    "import shapely\n",
    "\n",
    "# Plotting\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "conn_spa = spatialite.connect('../FPA_FOD_20170508.sqlite')\n",
    "sql = '''\n",
    "SELECT *, ST_AsBinary(Shape) as geom\n",
    "FROM Fires \n",
    "'''\n",
    "fpa = gpd.read_postgis(sql, conn_spa)\n",
    "fpa.head()\n",
    "conn_spa.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLEANING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpa['OWNER_CODE'] = fpa['OWNER_CODE'].astype(int)\n",
    "fpa['DISCOVERY_DATE'] = fpa['DISCOVERY_DATE'].map(lambda x: julian.from_jd(x))\n",
    "fpa['CONT_DATE'] = fpa['CONT_DATE'].map(lambda x: julian.from_jd(x) if np.isnan(x) == False else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpa.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling - Creating X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['FIRE_YEAR','DISCOVERY_DATE','DISCOVERY_DOY','DISCOVERY_TIME','LATITUDE','LONGITUDE','OWNER_CODE','STATE','COUNTY','FIPS_COMB']\n",
    "features = ['FIRE_YEAR','DISCOVERY_DATE','DISCOVERY_DOY','LATITUDE','LONGITUDE','OWNER_CODE', 'STATE']\n",
    "X = fpa[features]\n",
    "y = fpa['STAT_CAUSE_CODE'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['FIRE_MONTH'] = X['DISCOVERY_DATE'].map(lambda x: x.month)\n",
    "X = X.merge(pd.get_dummies(X['OWNER_CODE'], drop_first = True, prefix = \"owner_code\"), \n",
    "            how = 'inner',\n",
    "            left_index = True, \n",
    "            right_index = True)\n",
    "X.drop(columns = ['OWNER_CODE'], inplace= True)\n",
    "\n",
    "\n",
    "X = X.merge(pd.get_dummies(X['STATE'], drop_first = True), \n",
    "            how = 'inner',\n",
    "            left_index = True, \n",
    "            right_index = True)\n",
    "X.drop(columns = ['STATE', 'DISCOVERY_DATE'], inplace= True)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Decision Tree Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(criterion = 'gini', \n",
    "                            max_depth = 120, \n",
    "                            min_samples_split = 25, \n",
    "                            min_samples_leaf = 100)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Score on training set: {dt.score(X_train, y_train)}')\n",
    "print(f'Score on testing set: {dt.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCM = multilabel_confusion_matrix(y_test, preds, labels = [1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_test == 12).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switching to Cause by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_dict = {\n",
    "    1:'Lightning', # Natural\n",
    "    2:'Equipment Use', # Infrastructure\n",
    "    3:'Smoking', # Human\n",
    "    4:'Campfire', # Human\n",
    "    5:'Debris Burning', # Human\n",
    "    6:'Railroad', # Infrastructure\n",
    "    7:'Arson', # Human\n",
    "    8:'Children', # Human\n",
    "    9:'Miscellaneous', # Other\n",
    "    10:'Fireworks', # Human\n",
    "    11:'Powerline', # Infrastructure\n",
    "    12:'Structure', # Infrastructure\n",
    "    13:'Missing/Undefined' # Other\n",
    "}\n",
    "\n",
    "cat_dict = {\n",
    "    1:1,\n",
    "    2:2,\n",
    "    3:3,\n",
    "    4:3,\n",
    "    5:3,\n",
    "    6:2,\n",
    "    7:3,\n",
    "    8:3,\n",
    "    9:4,\n",
    "    10:3,\n",
    "    11:2,\n",
    "    12:2,\n",
    "    13:4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat = [cat_dict[i] for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_cat = DecisionTreeClassifier(criterion = 'gini', \n",
    "                            max_depth = 200, \n",
    "                            min_samples_split = 100, \n",
    "                            min_samples_leaf = 10)\n",
    "dt_cat.fit(X_train, y_train)\n",
    "print(f'Score on training set: {dt_cat.score(X_train, y_train)}')\n",
    "print(f'Score on testing set: {dt_cat.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_cat = dt_cat.predict(X_test)\n",
    "MCM = multilabel_confusion_matrix(y_test, preds_cat)\n",
    "MCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = params = {\n",
    "    'max_depth' : [100, 90, 110],\n",
    "    'min_samples_split' : [100,150,180],\n",
    "    'min_samples_leaf' : [30,40,50],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(DecisionTreeClassifier(random_state = 42), \n",
    "                    params,\n",
    "                    cv = 5, \n",
    "                    verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Start our timer.\n",
    "t0 = time.time()\n",
    "\n",
    "# Let's GridSearch over the above parameters on our training data.\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "# Stop our timer and print the result.\n",
    "print(f'This took {time.time() - t0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Score on training set: {grid.score(X_train, y_train)}')\n",
    "print(f'Score on testing set: {grid.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.cv_results_['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def collect_gridCV_results(model, name)\n",
    "    # Create a dataframe of model parameters, and results\n",
    "    model_history = pd.merge(pd.DataFrame(model.cv_results_['params']), \n",
    "             pd.DataFrame(model.cv_results_['mean_test_score'], columns = ['mean_test_score']),\n",
    "             how = 'inner',left_index = True, right_index = True)\n",
    "    # Append name column\n",
    "    model_history['model'] = name\n",
    "    return model_history\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier(n_estimators = 80, \n",
    "                            max_depth = 100, \n",
    "                            min_samples_split = 100, \n",
    "                            min_samples_leaf =40)\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Score on training set: {grid.score(X_train, y_train)}')\n",
    "print(f'Score on testing set: {grid.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Neural Network for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
